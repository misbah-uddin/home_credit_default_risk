{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Credit Default Risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Definition\n",
    "\n",
    "Many people struggle to get loans due to insufficient or non-existent credit histories. And, unfortunately, this population is often taken advantage of by untrustworthy lenders.\n",
    "\n",
    "Home Credit strives to broaden financial inclusion for the unbanked population by providing a positive and safe borrowing experience. In order to make sure this underserved population has a positive loan experience, Home Credit makes use of a variety of alternative data--including telco and transactional information--to predict their clients' repayment abilities.\n",
    "\n",
    "While Home Credit is currently using various statistical and machine learning methods to make these predictions, they're challenging Kagglers to help them unlock the full potential of their data. Doing so will ensure that clients capable of repayment are not rejected and that loans are given with a principal, maturity, and repayment calendar that will empower their clients to be successful."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "There are 7 different sources of data:\n",
    "\n",
    "application_train: \n",
    "- Main training data with information about each loan application at Home Credit \n",
    "- Every loan has its own row (`SK_ID_CURR`)\n",
    "- The value predict is given in `TARGET` column indicating 0 (the loan was repaid) or 1 (the loan was not repaid)\n",
    "\n",
    "application_test: \n",
    "- Main testing data with information about each loan application at Home Credit \n",
    "- Every loan has its own row (`SK_ID_CURR`)\n",
    "\n",
    "bureau: \n",
    "- Contains data about client's previous credits from other financial institutions\n",
    "- Each previous credit has its own row in bureau (identified by `SK_ID_BUREAU`)\n",
    "- One loan (`SK_ID_CURR`) in the application data can have multiple previous credits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import lightgbm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from seaborn import countplot, kdeplot\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import Imputer, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABEL_NAME = 'TARGET'\n",
    "CURRENT_LOAN_ID = 'SK_ID_CURR'\n",
    "PREVIOUS_LOAN_ID = 'SK_ID_PREV'\n",
    "BUREAU_LOAN_ID = 'SK_ID_BUREAU'\n",
    "ID_FEATURE_NAMES = [CURRENT_LOAN_ID, PREVIOUS_LOAN_ID, BUREAU_LOAN_ID]\n",
    "NUMERICAL_AGGREGATIONS = ['mean', 'max', 'min', 'sum']\n",
    "CATEGORICAL_AGGREGATIONS = ['mean', 'sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_test_features(train_data_path: str, test_data_path: str):\n",
    "    train_features = pd.read_csv(train_data_path)\n",
    "    test_features = pd.read_csv(test_data_path)\n",
    "    labels = train_features[LABEL_NAME]\n",
    "    \n",
    "    return train_features.drop(LABEL_NAME, axis=1), test_features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = 'data/application_train.csv'\n",
    "test_data_path = 'data/application_test.csv'\n",
    "train_features, test_features, labels = get_train_test_features(train_data_path, test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((307511, 121), (307511,), (48744, 121))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape, labels.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_aggregate_column_names(column_names: list, exclude_item: str):\n",
    "    new_column_names = []\n",
    "    for column_name, agg_name in column_names:\n",
    "        if column_name is exclude_item:\n",
    "            new_column_names.append(column_name)\n",
    "        else:\n",
    "            new_column_names.append('{}_{}'.format(column_name, agg_name))\n",
    "    return new_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extend_features(df: pd.DataFrame, exclude_feature: str, grouping_feature: str):\n",
    "    categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "    numerical_columns = df.columns.difference([exclude_feature]).difference(categorical_columns)\n",
    "    \n",
    "    numerical_group = df[numerical_columns].groupby(grouping_feature)\n",
    "    numercial_aggregate = numerical_group.agg(NUMERICAL_AGGREGATIONS).reset_index()\n",
    "    numercial_aggregate.columns = create_aggregate_column_names(numercial_aggregate.columns.ravel(), \n",
    "                                                                exclude_item=grouping_feature)\n",
    "    \n",
    "    category_df = pd.get_dummies(df[categorical_columns])\n",
    "    category_df[grouping_feature] = df[grouping_feature]\n",
    "    category_group = category_df.groupby(grouping_feature)\n",
    "    category_aggregate = category_group.agg([CATEGORICAL_AGGREGATIONS]).reset_index()\n",
    "    category_aggregate.columns = create_aggregate_column_names(category_aggregate.columns.ravel(), \n",
    "                                                               exclude_item=grouping_feature)\n",
    "    \n",
    "    combined_df = numercial_aggregate.merge(category_aggregate, on=grouping_feature)\n",
    "    if exclude_feature:\n",
    "        combined_df = combined_df.merge(df[[grouping_feature, exclude_feature]], on=grouping_feature)\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extend_train_test_data_two_level(level_one_data_path: str, \n",
    "                                     level_one_exclude_feature: str, \n",
    "                                     level_one_grouping_feature: str,\n",
    "                                     level_two_data_path: str, \n",
    "                                     level_two_exclude_feature: str, \n",
    "                                     level_two_grouping_feature: str,\n",
    "                                     train_df: pd.DataFrame, \n",
    "                                     test_df: pd.DataFrame):\n",
    "    level_one_df = pd.read_csv(level_one_data_path)\n",
    "    level_one_aggregated = extend_features(df=level_one_df,\n",
    "                                           exclude_feature=level_one_exclude_feature, \n",
    "                                           grouping_feature=level_one_grouping_feature\n",
    "                                          ).drop_duplicates(level_one_grouping_feature)\n",
    "    level_two_df = pd.read_csv(level_two_data_path)\n",
    "    level_two_df_extended = level_two_df.merge(level_one_aggregated, how='left', on=level_one_grouping_feature)\n",
    "    level_two_aggregated = extend_features(df=level_two_df_extended, \n",
    "                                           exclude_feature=level_two_exclude_feature, \n",
    "                                           grouping_feature=level_two_grouping_feature\n",
    "                                          ).drop_duplicates(level_two_grouping_feature)\n",
    "    train_df = train_df.merge(level_two_aggregated, how='left', on=level_two_grouping_feature)\n",
    "    test_df = test_df.merge(level_two_aggregated, how='left', on=level_two_grouping_feature)\n",
    "        \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_balance_data_path = 'data/bureau_balance.csv'\n",
    "bureau_data_path = 'data/bureau.csv'\n",
    "\n",
    "bureau_balance_exclude_feature = ''\n",
    "bureau_exclude_feature = BUREAU_LOAN_ID\n",
    "\n",
    "bureau_balance_grouping_feature = BUREAU_LOAN_ID\n",
    "bureau_grouping_feature = CURRENT_LOAN_ID\n",
    "\n",
    "train_features, test_features = extend_train_test_data_two_level(\n",
    "    level_one_data_path=bureau_balance_data_path,\n",
    "    level_one_exclude_feature=bureau_balance_exclude_feature, \n",
    "    level_one_grouping_feature=bureau_balance_grouping_feature,\n",
    "    level_two_data_path=bureau_data_path, \n",
    "    level_two_exclude_feature=bureau_exclude_feature, \n",
    "    level_two_grouping_feature=bureau_grouping_feature,\n",
    "    train_df=train_features, \n",
    "    test_df=test_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((307511, 241), (48744, 241))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_train_test_data_one_level(df_path: str, \n",
    "                                     exclude_feature: str, \n",
    "                                     grouping_feature: str,\n",
    "                                     train_df: pd.DataFrame, \n",
    "                                     test_df: pd.DataFrame):\n",
    "    extend_df = pd.read_csv(df_path)\n",
    "    extend_aggregate = extend_features(df=extend_df, \n",
    "                                       exclude_feature=exclude_feature, \n",
    "                                       grouping_feature=grouping_feature).drop_duplicates(CURRENT_LOAN_ID)\n",
    "    train_df = train_df.merge(extend_aggregate, how='left', on=grouping_feature)\n",
    "    test_df = test_df.merge(extend_aggregate, how='left', on=grouping_feature)\n",
    "        \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extend train and test data with auxiliary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((307511, 461), (48744, 461))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_path = 'data/previous_application.csv'\n",
    "train_features, test_features = extend_train_test_data_one_level(df_path=df_path,\n",
    "                                                                 exclude_feature=PREVIOUS_LOAN_ID, \n",
    "                                                                 grouping_feature=CURRENT_LOAN_ID, \n",
    "                                                                 train_df=train_features, \n",
    "                                                                 test_df=test_features)\n",
    "train_features.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.to_csv('input/train.csv')\n",
    "test_features.to_csv('input/test.csv')\n",
    "labels.to_csv('input/labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with category data by one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_one_hot_encoded(train_features: pd.DataFrame, test_features: pd.DataFrame):\n",
    "    train_1h = pd.get_dummies(train_features)\n",
    "    test_1h = pd.get_dummies(test_features)\n",
    "    \n",
    "    return train_1h.align(test_1h, join='inner', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((307511, 582), (48744, 582))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features, test_features = make_one_hot_encoded(train_features, test_features)\n",
    "train_features.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def impute(train_data: pd.DataFrame, test_data: pd.DataFrame, strategy: str) -> tuple:\n",
    "    imputer = Imputer(strategy=strategy)\n",
    "    \n",
    "    train_imputed = imputer.fit_transform(train_data)\n",
    "    train_features = pd.DataFrame(train_imputed, columns=train_data.columns)\n",
    "    \n",
    "    test_imputed = imputer.transform(test_data) \n",
    "    test_features = pd.DataFrame(test_imputed, columns=test_data.columns)\n",
    "    \n",
    "    return train_features, test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((307511, 582), (48744, 582))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features, test_features = impute(train_features, test_features, strategy='median')\n",
    "train_features.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(train_data: pd.DataFrame, test_data: pd.DataFrame, feature_range):\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=feature_range)\n",
    "    train_ids = train_data[CURRENT_LOAN_ID].apply(int)\n",
    "    test_ids = test_data[CURRENT_LOAN_ID].apply(int)\n",
    "    train_scaled = scaler.fit_transform(train_data)\n",
    "    test_scaled = scaler.transform(test_data)\n",
    "    train_data_scaled = pd.DataFrame(train_scaled, columns=train_data.columns )\n",
    "    test_data_scaled = pd.DataFrame(test_scaled, columns=test_data.columns)\n",
    "    \n",
    "    train_data_scaled[CURRENT_LOAN_ID] = train_ids\n",
    "    test_data_scaled[CURRENT_LOAN_ID] = test_ids\n",
    "    \n",
    "    return test_data_scaled, test_data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48744, 582), (48744, 582))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features, test_features = scale(train_features, test_features, feature_range=(0, 1))\n",
    "train_features.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gbm_model(train: pd.DataFrame, target: pd.DataFrame, test: pd.DataFrame, id_field: str, n_splits: int):\n",
    "    feature_columns = list(set(train.columns).difference(id_field))\n",
    "    train_ids = train[id_field]\n",
    "    train_wo_ids = train[feature_columns]\n",
    "    test_wo_ids = test[feature_columns]\n",
    "    \n",
    "    train_matrix = train_wo_ids.as_matrix()\n",
    "    target_matrix = target.as_matrix()\n",
    "    test_matrix = test_wo_ids.as_matrix()\n",
    "    \n",
    "    k_fold = KFold(n_splits=n_splits, shuffle=False, random_state=50)\n",
    "    test_predictions = np.zeros(test_wo_ids.shape[0])\n",
    "    feature_importances = np.zeros(len(feature_columns))\n",
    "    out_of_fold = np.zeros(train.shape[0])\n",
    "    \n",
    "    valid_scores = []\n",
    "    train_scores = []\n",
    "    \n",
    "    for train_indices, valid_indices in k_fold.split(train_matrix):\n",
    "        model = lightgbm.LGBMClassifier(n_estimators=10000, \n",
    "                                        objective='binary', \n",
    "                                        class_weight='balanced', \n",
    "                                        learning_rate=0.05, \n",
    "                                        reg_alpha=0.1, \n",
    "                                        reg_lambda=0.1, \n",
    "                                        subsample=0.8, \n",
    "                                        n_jobs=-1, \n",
    "                                        random_state=50)\n",
    "        train_feature_sample = train_matrix[train_indices]\n",
    "        train_target_sample = target_matrix[train_indices]\n",
    "        valid_feature_sample = train_matrix[valid_indices]\n",
    "        valid_target_sample = target_matrix[valid_indices]\n",
    "        \n",
    "        model.fit(train_feature_sample, \n",
    "                  train_target_sample, \n",
    "                  eval_metric='auc', \n",
    "                  eval_set=[(valid_feature_sample, valid_target_sample), \n",
    "                            (train_feature_sample, train_target_sample)], \n",
    "                  eval_names=['valid', 'train'], \n",
    "                  categorical_feature='auto', \n",
    "                  early_stopping_rounds=100, \n",
    "                  verbose=200)\n",
    "    \n",
    "        feature_importances += model.feature_importances_ / k_fold.n_splits\n",
    "        \n",
    "        test_predictions += model.predict_proba(test_matrix, num_iteration=model.best_iteration_)[ :,1]/k_fold.n_splits\n",
    "        \n",
    "        out_of_fold[valid_indices] = model.predict_proba(valid_feature_sample, num_iteration=model.best_iteration_)[ :,1]\n",
    "        \n",
    "        valid_scores.append(model.best_score_['valid']['auc'])\n",
    "        train_scores.append(model.best_score_['train']['auc'])\n",
    "        \n",
    "        gc.enable()\n",
    "        del model, train_feature_sample, valid_feature_sample\n",
    "        gc.collect()\n",
    "        \n",
    "    submission = pd.DataFrame({id_field: test[id_field], 'TARGET': test_predictions})\n",
    "    \n",
    "    feature_importances_pd = pd.DataFrame({'feature': feature_columns, 'importance': feature_importances})\n",
    "    \n",
    "    valid_auc = roc_auc_score(target_matrix, out_of_fold)    \n",
    "    \n",
    "    metrics = pd.DataFrame({'fold': list(range(n_splits)), \n",
    "                            'train': train_scores.append(np.mean(train_scores)),\n",
    "                            'valid': valid_scores.append(valid_auc)})\n",
    "    \n",
    "    return submission, feature_importances_pd, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid's auc: 0.499569\ttrain's auc: 0.93345\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid's auc: 0.519155\ttrain's auc: 0.574629\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid's auc: 0.512492\ttrain's auc: 0.742154\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid's auc: 0.516183\ttrain's auc: 0.888119\n",
      "Training until validation scores don't improve for 100 rounds.\n"
     ]
    }
   ],
   "source": [
    "submission, feature_importances, metrics = gbm_model(train=train_features, \n",
    "                                                     target=labels, \n",
    "                                                     test=test_features, \n",
    "                                                     id_field=CURRENT_LOAN_ID, \n",
    "                                                     n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('gbm_feature_submission_6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
